---
layout: page
title: Keynote Talks
description: Keynote talks, with title, abstract and speaker bios.
priority: 8
invisible: false
published: true
---


<div id="k1" class="talk">
  <div class="talk-profile">
    <img src="{{site.baseurl}}/images/keynote_2.jpg"/>
  </div>
  <div class="talk-speaker">
    <h3>Dieter Fox</h3>
    <h4>Senior Director of Robotics Research at NVIDIA</h4>
    <h4>Professor at the University of Washington</h4>
  </div>
</div>

## Where is RobotGPT?
{: class="talk-title"}

**Abstract:** The last years have seen astonishing progress in the capabilities of generative AI techniques, particularly in the areas of language and visual understanding and generation. Key to the success of these models are the use of image and text data sets of unprecedented scale along with models that are able to digest such large datasets.  We are now seeing the first examples of leveraging such models to equip robots with open-world visual understanding and reasoning capabilities.  Unfortunately, however, we have not achieved the RobotGPT moment; these models still struggle with reasoning about geometry and physical interactions in the real world, resulting in brittle performance on seemingly simple tasks such as manipulating objects in the open world.  A crucial reason for this problem is the lack of data suitable to train powerful, general models for robot decision making and control.
In this talk, I will discuss approaches to generating large datasets for training robot manipulation capabilities, with a focus on the role simulation can play in this context.  I will show some of our prior work, where we demonstrated robust sim-to-real transfer of manipulation skills trained in simulation, and then present a path toward generating large scale demonstration sets that could help train robust, open-world robot manipulation models.


**Bio:** Dieter Fox is Senior Director of Robotics Research at NVIDIA and Professor in the Allen School of Computer Science & Engineering at the University of Washington, where he heads the UW Robotics and State Estimation Lab. Dieter's research is in robotics and artificial intelligence, with a focus on learning and perception applied to problems such as robot manipulation, mapping, and object detection and tracking. He has published more than 200 technical papers and is the co-author of the textbook “Probabilistic Robotics”. He is a Fellow of the IEEE, AAAI, and ACM, and recipient of the 2020 IEEE Pioneer in Robotics and Automation Award and the 2023 IJCAI John McCarthy Award.  He was an editor of the IEEE Transactions on Robotics, program co-chair of the 2008 AAAI Conference on Artificial Intelligence, and program chair of the 2013 Robotics: Science and Systems conference.

<br/>
<hr>
<br/>


<!-- 
<div id="k2" class="talk">
  <div class="talk-profile">
    <img src="{{site.baseurl}}/images/keynote_1.jpg"/>
  </div>
  <div class="talk-speaker">
    <h3>Jamie Paik</h3>
    <h4>Professor</h4>
    <h4>Director, Reconfigurable Robotics Laboratory</h4>
    <h4>Ecole Polytechnique Federale de Lausanne (EPFL)</h4>
  </div>
</div>

## Reconfigurable Robots for Physical Interactions
{: class="talk-title"}

**Abstract:** A truly ubiquitous environment is where human-machine interactions are intuitive, reliable, and compatible. This requires an intelligent platform that is versatile and adaptable to evolving tasks and dynamic environments. While there are extensive efforts in addressing this challenge through massive data and learning algorithms, there is yet to be a cohesive solution to improve the actual physical interactions. Recent developments in soft robots with their unconventional material-based solutions and modular robots with a multitude of configurations propose possible avenues to extend the capacities of robotics. This talk will highlight the recent progress in soft-material robots and reconfigurable origami robots that aim at achieving comprehensive solutions toward diverse "softer" human-robot applications.

**Bio:** Prof. Jamie Paik is director and founder of Reconfigurable Robotics Lab (RRL) of Swiss Federal Institute of Technology (EPFL) and a core member of Swiss National Centers of Competence in Research (NCCR) Robotics consortium. RRL’s research leverages expertise in design and advanced manufacturing toward reconfigurable robotic platforms that push the physical limits of material and mechanisms. Her latest research effort is in soft robotics and self-morphing Robogami (robotic origami). Robogami transforms autonomously its planar shape to 2D or 3D by folding like the paper art, origami. Soft material robots and robogamis are designed to be interactive with the users and their environments through both innate and active reconfigurations. Such characteristics of the RRL’s robots have direct applications in medical, automobile, space, communication, and wearable robots. While this novel technology has been published in multiple academic journals such as in Soft Robotics Journal, IEEE Transactions in Robotics, Nature, and Science, RRL’s spin-offs, MIROS and Foldaway-Haptics, have pushed the boundaries of the industrial applications of these robots as seen in TED conferences 2019 and 2023. One of the robogamis was a part of Mercedez’s 2020 concept car, AVTR, presented during CES 2020, and MIROS in CES 2023.
-->